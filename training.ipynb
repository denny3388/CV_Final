{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom PIL import Image, ImageOps\nimport time\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mplt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as transforms\nfrom torchvision import models\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split # for splitting the data into train and test samples\nfrom sklearn.metrics import classification_report # for model evaluation metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2022-06-11T09:08:19.38327Z","iopub.execute_input":"2022-06-11T09:08:19.383671Z","iopub.status.idle":"2022-06-11T09:08:22.194326Z","shell.execute_reply.started":"2022-06-11T09:08:19.383591Z","shell.execute_reply":"2022-06-11T09:08:22.193481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, path):\n    with open(path, 'rb') as f:\n        img = Image.open(f)\n        gray_image = ImageOps.grayscale(img)\n        data = np.array(gray_image)\n        \n        data = torch.tensor(data)\n        data = data.unsqueeze(0) # (28, 28) -> (1, 28, 28) [add batch]\n\n    output = model(data.float())\n    print(output)\n    result = torch.argmax(output)\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-06-11T09:08:22.196604Z","iopub.execute_input":"2022-06-11T09:08:22.197201Z","iopub.status.idle":"2022-06-11T09:08:22.20413Z","shell.execute_reply.started":"2022-06-11T09:08:22.197143Z","shell.execute_reply":"2022-06-11T09:08:22.202768Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_accuracy(batch, output, label):\n    y_pred = []\n    for i in range(batch):\n        o = list(output[i])\n        idx = o.index(max(o))\n        y_pred.append(idx)\n    y_true = list(label)\n    return accuracy_score(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T09:08:22.205701Z","iopub.execute_input":"2022-06-11T09:08:22.206296Z","iopub.status.idle":"2022-06-11T09:08:22.214513Z","shell.execute_reply.started":"2022-06-11T09:08:22.206255Z","shell.execute_reply":"2022-06-11T09:08:22.213551Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(model, dataloader, GPU):        \n    for i, (data, label) in enumerate(dataloader):\n\n        if GPU:\n            data, label = data.cuda(), label.cuda()\n\n        # Forward prop.\n        output = model(data.float()) \n        # Get loss & accuracy\n        loss = criterion(output, label)\n        this_epoch_accuracy += get_accuracy(output.shape[0], output.cpu(), label.cpu())\n        this_epoch_loss += loss\n    \n    end = time.time()\n    print('[*] Epoch {}: loss = {:.4f}, accuracy = {:.4f}, time = {:.1f}s'.format(epoch+1, this_epoch_loss, this_epoch_accuracy/(i+1), end-start))\n\n    accuracy = accuracy_score(y_true, y_pred)\n    matrix = confusion_matrix(y_true, y_pred)\n    report = classification_report(y_true, y_pred)\n    return accuracy, matrix, report","metadata":{"execution":{"iopub.status.busy":"2022-06-11T09:08:22.217144Z","iopub.execute_input":"2022-06-11T09:08:22.217637Z","iopub.status.idle":"2022-06-11T09:08:22.226052Z","shell.execute_reply.started":"2022-06-11T09:08:22.217565Z","shell.execute_reply":"2022-06-11T09:08:22.225025Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self): \n        super(CNN, self).__init__()\n        self.class_num = 10\n        self.input_size = 28\n        \n        self.block1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0), # (1, 28, 28) -> (16, 24, 24)\n            nn.BatchNorm2d(16),\n            nn.Dropout2d(p=0.1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)) # (16, 24, 24) -> (16, 12, 12)\n        \n        self.block2 = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0), # (16, 12, 12) -> (32, 8, 8)\n            nn.BatchNorm2d(32),\n            nn.Dropout2d(p=0.1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)) # (32, 8, 8) -> (32, 4, 4)\n\n        self.fc = nn.Linear(32 * 4 * 4, self.class_num)\n\n    def forward(self, x):\n        out = self.block1(x)\n        out = self.block2(out)\n        out = out.view(out.size(0), -1)\n        out = self.fc(out) # (batch, 32 * 4 * 4) -> (batch, 10)\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-06-11T09:08:22.227909Z","iopub.execute_input":"2022-06-11T09:08:22.228685Z","iopub.status.idle":"2022-06-11T09:08:22.24167Z","shell.execute_reply.started":"2022-06-11T09:08:22.228643Z","shell.execute_reply":"2022-06-11T09:08:22.240538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Ensemble(nn.Module):\n    def __init__(self, models): \n        super(Ensemble, self).__init__()\n        self.class_num = 10\n        self.input_size = 28\n        \n        self.models = models\n        self.fc = nn.Linear(self.class_num * len(models), self.class_num)\n\n    def forward(self, x):\n        outs = [model(x) for model in self.models]\n        out = torch.cat(outs, dim=1)\n        out = self.fc(out) # (batch, 32 * 4 * 4) -> (batch, 10)\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-06-11T09:08:22.24496Z","iopub.execute_input":"2022-06-11T09:08:22.24535Z","iopub.status.idle":"2022-06-11T09:08:22.254067Z","shell.execute_reply.started":"2022-06-11T09:08:22.245319Z","shell.execute_reply":"2022-06-11T09:08:22.253295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %load dataset.py \nimport torch.utils.data as data\n\nfrom PIL import Image\n\nimport os\nimport os.path\n\nIMG_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif']\n\ndef has_file_allowed_extension(filename, extensions):\n    \"\"\"Checks if a file is an allowed extension.\n\n    Args:\n        filename (string): path to a file\n\n    Returns:\n        bool: True if the filename ends with a known image extension\n    \"\"\"\n    filename_lower = filename.lower()\n    return any(filename_lower.endswith(ext) for ext in extensions)\n\n\ndef make_dataset(dir):\n    images = []\n    for root, _, fnames in sorted(os.walk(dir)):\n        for fname in sorted(fnames):\n            path = os.path.join(root, fname)\n            img = pil_loader(path)\n            class_num = root.split(dir)[1][1]\n            item = (img, int(class_num))\n            images.append(item)\n\n    return images\n\n\nclass DatasetFolder(data.Dataset):\n    def __init__(self, root, transform=None, target_transform=None):\n        # classes, class_to_idx = find_classes(root)\n        samples = make_dataset(root)\n        if len(samples) == 0:\n            raise(RuntimeError(\"Found 0 files in subfolders of: \" + root + \"\\n\"\n                               \"Supported extensions are: \" + \",\".join(extensions)))\n\n        self.root = root\n        self.samples = samples\n\n        self.transform = transforms.ToTensor()\n        self.target_transform = target_transform\n\n    def __getitem__(self, index):\n        \"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (sample, target) where target is class_index of the target class.\n        \"\"\"\n        sample, target = self.samples[index]\n        #sample = pil_loader(path)\n        #sample = torch.tensor(sample)\n        if self.transform is not None:\n            sample = self.transform(sample)\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return sample, target\n\n    def __len__(self):\n        return len(self.samples)\n\ndef pil_loader(path):\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    \n    return img","metadata":{"execution":{"iopub.status.busy":"2022-06-11T09:08:23.106311Z","iopub.execute_input":"2022-06-11T09:08:23.106731Z","iopub.status.idle":"2022-06-11T09:08:23.138706Z","shell.execute_reply.started":"2022-06-11T09:08:23.106696Z","shell.execute_reply":"2022-06-11T09:08:23.137832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_on_GPU = False\n\nif torch.cuda.is_available():\n    train_on_GPU = True\n    my_device = torch.device('cuda')\nelse:\n    my_device = torch.device('cpu')\nprint('using device: {}'.format(my_device))","metadata":{"execution":{"iopub.status.busy":"2022-06-11T09:08:23.911962Z","iopub.execute_input":"2022-06-11T09:08:23.912653Z","iopub.status.idle":"2022-06-11T09:08:23.982314Z","shell.execute_reply.started":"2022-06-11T09:08:23.912614Z","shell.execute_reply":"2022-06-11T09:08:23.981338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\" Dataset Construction \"\"\"\nmodel_num = 3\nbatch_size = 512\ntrain_dir = []\ntrain_dir.append('../input/2022-cv-final/training data/training data')\ntrain_dir.append('../input/2022-cv-final/training data 2/training data 2')\ntrain_dir.append('../input/2022-cv-final/training data 3/training data 3')\nvalid_dir = '../input/2022-cv-final/validation data/validation data'\n\nDataloaders = []\nfor i in range(model_num):\n    Dataloaders.append(DataLoader(dataset=DatasetFolder(train_dir[i]), batch_size=batch_size, shuffle=True))\n    print('Dataset {} complete!'.format(i))\n#myDataloader = DataLoader(dataset=DatasetFolder(root_dir), batch_size=batch_size, shuffle=True)\nvalidDataloader = DataLoader(dataset=DatasetFolder(valid_dir), batch_size=128, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T09:22:52.074425Z","iopub.execute_input":"2022-06-11T09:22:52.074779Z","iopub.status.idle":"2022-06-11T09:30:06.408048Z","shell.execute_reply.started":"2022-06-11T09:22:52.074749Z","shell.execute_reply":"2022-06-11T09:30:06.407223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\" Model Construction \"\"\"\nmodels = []\noptims = []\nfor i in range(model_num):\n    models.append(CNN().float())\n    optims.append(torch.optim.Adam(models[i].parameters(), lr=0.002))\n\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2022-06-11T10:18:21.846612Z","iopub.execute_input":"2022-06-11T10:18:21.846974Z","iopub.status.idle":"2022-06-11T10:18:21.85927Z","shell.execute_reply.started":"2022-06-11T10:18:21.846942Z","shell.execute_reply":"2022-06-11T10:18:21.858361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\" Training \"\"\"\n# Set hyperparameters\nepochs_num = 40\nsave_freq = 10\nvalid_freq = 5\nload = False\n\nfor m_idx in range(model_num):\n    \n    if train_on_GPU:\n        models[m_idx] = models[m_idx].cuda()\n        \n    best_accuracy = 0\n    best_param = {}\n    \n    ### Load pretrained model ###\n    if(load): \n        models[m_idx].load_state_dict(torch.load('../input/ml-hw5-train/k_model_weights_300.pth'))\n        print('Load model success!')\n\n    ### Main training process ###\n    print(\"-----Start training!-----\")\n    start = time.time()\n    for epoch in range(epochs_num):\n        this_epoch_loss = 0\n        this_epoch_accuracy = 0\n\n        for i, (data, label) in enumerate(Dataloaders[0]):\n\n            if train_on_GPU:\n                data, label = data.cuda(), label.cuda()\n\n            # Clear gradient\n            optims[m_idx].zero_grad()\n\n            # Forward prop.\n            output = models[m_idx](data.float()) \n\n            # Get loss & accuracy\n            loss = criterion(output, label)\n            this_epoch_accuracy += get_accuracy(output.shape[0], output.cpu(), label.cpu())\n            this_epoch_loss += loss\n\n            # Backward prop.\n            loss.backward()\n\n            # Update parameters\n            optims[m_idx].step()\n\n        end = time.time()\n        print('[*] Epoch {}: loss = {:.4f}, accuracy = {:.4f}, time = {:.1f}s'.format(epoch+1, this_epoch_loss, this_epoch_accuracy/(i+1), end-start))\n\n        ### Validation ###\n        if ((epoch+1) % valid_freq == 0):\n            valid_loss = 0\n            valid_accuracy = 0\n            for i, (data, label) in enumerate(validDataloader):\n\n                if train_on_GPU:\n                    data, label = data.cuda(), label.cuda()\n\n                output = models[m_idx](data.float()) \n                loss = criterion(output, label)\n                valid_accuracy += get_accuracy(output.shape[0], output.cpu(), label.cpu())\n                valid_loss += loss\n\n            end = time.time()\n            print('[-] Validation: loss = {:.4f}, accuracy = {:.4f}, time = {:.1f}s'.format(valid_loss, valid_accuracy/(i+1), end-start))\n            \n            if(valid_accuracy/(i+1) > best_accuracy):\n                best_accuracy = valid_accuracy/(i+1)\n                best_param = models[m_idx].state_dict()\n                # save\n                name = 'model_' + str(m_idx) + '_weights' + '.pth'\n                torch.save(models[m_idx].state_dict(), name)\n                print('Save model success!')\n\n        \"\"\"### Save model ###\n        if ((epoch+1) % save_freq == 0):\n            name = 'model_weights_' + str(epoch+1) + '.pth'\n            torch.save(TrainModel.state_dict(), name)\n            print('Save model success!')\"\"\"\n        \n    ### Choose best param ###\n    models[m_idx].load_state_dict(best_param)\n    print('-------- Model {} training complete! --------'.format(m_idx))","metadata":{"execution":{"iopub.status.busy":"2022-06-11T10:18:22.761744Z","iopub.execute_input":"2022-06-11T10:18:22.762098Z","iopub.status.idle":"2022-06-11T10:37:04.111276Z","shell.execute_reply.started":"2022-06-11T10:18:22.762069Z","shell.execute_reply":"2022-06-11T10:37:04.108613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\" Ensemble Model Construction \"\"\"\nMainModel = Ensemble(models).float()\noptimizer = torch.optim.Adam(MainModel.parameters(), lr=0.002)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2022-06-11T10:37:04.113417Z","iopub.execute_input":"2022-06-11T10:37:04.113761Z","iopub.status.idle":"2022-06-11T10:37:04.122455Z","shell.execute_reply.started":"2022-06-11T10:37:04.113725Z","shell.execute_reply":"2022-06-11T10:37:04.121457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\" Training \"\"\"\n# Set hyperparameters\nepochs_num = 40\nsave_freq = 10\nvalid_freq = 5\nload = False\n\nif train_on_GPU:\n    MainModel = MainModel.cuda()\n\nbest_accuracy = 0\nbest_param = {}\n\n### Load pretrained model ###\nif(load): \n    MainModel.load_state_dict(torch.load('../input/ml-hw5-train/k_model_weights_300.pth'))\n    print('Load model success!')\n\n### Main training process ###\nprint(\"-----Start training!-----\")\nstart = time.time()\nfor epoch in range(epochs_num):\n    this_epoch_loss = 0\n    this_epoch_accuracy = 0\n\n    for i, (data, label) in enumerate(Dataloaders[0]):\n\n        if train_on_GPU:\n            data, label = data.cuda(), label.cuda()\n\n        # Clear gradient\n        optimizer.zero_grad()\n\n        # Forward prop.\n        output = MainModel(data.float()) \n\n        # Get loss & accuracy\n        loss = criterion(output, label)\n        this_epoch_accuracy += get_accuracy(output.shape[0], output.cpu(), label.cpu())\n        this_epoch_loss += loss\n\n        # Backward prop.\n        loss.backward()\n\n        # Update parameters\n        optimizer.step()\n\n    end = time.time()\n    print('[*] Epoch {}: loss = {:.4f}, accuracy = {:.4f}, time = {:.1f}s'.format(epoch+1, this_epoch_loss, this_epoch_accuracy/(i+1), end-start))\n\n    ### Validation ###\n    if ((epoch+1) % valid_freq == 0):\n        valid_loss = 0\n        valid_accuracy = 0\n        for i, (data, label) in enumerate(validDataloader):\n\n            if train_on_GPU:\n                data, label = data.cuda(), label.cuda()\n\n            output = MainModel(data) \n            loss = criterion(output, label)\n            valid_accuracy += get_accuracy(output.shape[0], output.cpu(), label.cpu())\n            valid_loss += loss\n\n        end = time.time()\n        print('[-] Validation: loss = {:.4f}, accuracy = {:.4f}, time = {:.1f}s'.format(valid_loss, valid_accuracy/(i+1), end-start))\n\n        if(valid_accuracy/(i+1) > best_accuracy):\n            best_accuracy = valid_accuracy/(i+1)\n            best_param = MainModel.state_dict()\n            # save\n            name = 'model_main_weights.pth'\n            torch.save(MainModel.state_dict(), name)\n            print('Save model success!')\n\n    \"\"\"### Save model ###\n    if ((epoch+1) % save_freq == 0):\n        name = 'model_weights_' + str(epoch+1) + '.pth'\n        torch.save(TrainModel.state_dict(), name)\n        print('Save model success!')\"\"\"\n        \n### Choose best param ###\nMainModel.load_state_dict(best_param)\nprint('-------- Main Model training complete! --------')","metadata":{"execution":{"iopub.status.busy":"2022-06-11T10:37:04.124235Z","iopub.execute_input":"2022-06-11T10:37:04.124701Z","iopub.status.idle":"2022-06-11T10:43:34.628537Z","shell.execute_reply.started":"2022-06-11T10:37:04.124659Z","shell.execute_reply":"2022-06-11T10:43:34.627754Z"},"trusted":true},"execution_count":null,"outputs":[]}]}